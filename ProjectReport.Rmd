---
title: Exploring the Differences of Attitudes towards the Future of AI among Developers with Various
  Backgrounds
subtitle: BIOSTAT 625 Final Project Report
author: Aonan Chen, Guoxuan Ma, Ruoxuan Mao and Zixi Wang
date: Dec 13, 2021
output: pdf_document
---

## 1. Introduction

Even though the term “AI” has become a trending topic that attracts the attention of lots of the public, the definition of artificial intelligence (AI) has remained ambiguous [1]. There is no well-accepted universal interpretation for artificial intelligence since a 2018 survey identified hundreds of definitions of intelligence [5]. Some people define artificial intelligence by referring to human intelligence, which can be seen as the problem of “making a machine behave in ways that would be called intelligent if a human were so behaving” [4]. Some people specify AI as “a system’s ability to interpret external data correctly, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation” [2]. Despite all different definitions, a consensus about AI is that “it is associated with machines and computers to help humankind solve problems and facilitate working processes” [3]. Though AI is still under development, the application of weak AI has been widely used in everyday life such as Siri, self-driving cars, etc. Since the AI industry is booming, we are interested in exploring whether people with various backgrounds tend to have different attitudes towards the future of AI. 

The dataset that we used to answer such a question is obtained by the 2018 Stack Overflow developer survey. Stack Overflow developer survey is a survey that Stack Overflow publishes annually to collect information from the developer community about their profiles, technologies, and work-related questions. That we are particularly interested in the survey of 2018 is because the Stack Overflow survey team covered a few new topics ranging from artificial intelligence to ethics in coding. Due to the nature of the survey, we are unable to explore if there are differences in attitudes towards AI among the general public because respondents were recruited primarily through channels owned by Stack Overflow (i.e. most of them are somehow interacting with coding). Therefore, our question of interest becomes whether coders/developers with various backgrounds have different attitudes towards AI. In particular, we would like to see whether there is such difference on programmer's opinions on the future of AI. If such difference stands, we are further interested to explore whether a significant effect is positive or negative. 

## 2. Data Description and  Data Cleaning 

### 2.1 Data Description

Our data set was collected and published by the Stack Overflow website and was also the full, cleaned results of the 2018 Stack Overflow Developer Survey. The Survey included 129 questions, most of which are multiple choices questions covering education, employment, coding experience & habits, demographic information, attitudes towards different topics and Stack Overflow product feedback and review. All the respondents were recruited primarily through channels owned by Stack Overflow. In the released version, there are 98,855 responses in total. The survey responses are publickly available at https://insights.stackoverflow.com/survey/2018. The outcome variable of interest comes from the question below with three options:

* Overall, what's your take on the future of artificial intelligence?
  + I'm worried about the dangers more than I'm excited about the possibilities.
  + I'm excited about the possibilities more than worried about the dangers.
  + I don't care about it, or I haven't thought about it.

### 2.2 Data Cleaning

#### 2.2.1 Delete irrelevant questions

Because our problem of interest is whether coders/developers with various backgrounds have different attitudes towards the future of AI, there are many questions not related to the problem of interest in the original survey, such as attitudes towards advertisements on Stack Overflow, activity or engagement on Stack Overflow, product feedback, etc. Therefore, we screened all the questions in the survey and manually deleted those irrelevant questions in order to prevent interference with the later model. After deleting, there are still 52 questions remaining. 

#### 2.2.2 Convert categorical variables to binary dummy variables

For continuous variables (e.g., salary) in the data set, we can directly use them in modelling. However, for categorical variables, we are supposed to use reference cell coding method to convert them to binary dummy variables. For example, in terms of the variable Hobby, there are two different categories: Yes and No. Therefore, we choose the No category to be the reference group and encode the two categories into one dummy variable with binary value. In the data set, we also make some special transformations of the categorical variables. For instance, because the satisfaction variables assume that differences between adjacent groups are equal and there is an increasing trend under sequential categories, we convert job and career satisfaction into ordinal integer scores (1: extremely dissatisfied, 7: extremely satisfied). In addition, we decide to convert country to continent using country code because there are too many types of country variables.

#### 2.2.3 Fill in missing values

After prescreening, there is only 3846 complete responses out of 98,855 responses. If we simply drop all the cases with NA, we will lose a substantial amount of information. The following steps are how we deal with NAs. Firstly, we drop responses with more than 50% unanswered questions. We regard the responses with more than half of the questions unanswered as invalid responses. Then, we use the KNN method to impute all the missing values. After imputation, we obtain a feature matrix of 69,083 samples and 357 independent variables. 

## 3. Methods

To answer our proposed question of interest, we consider methods of classification over regression since our outcome variable of interest is categorical. Potential methods for the purpose of multi-category classification include KNN, logistic regression, SVM, tree-based methods, neural network, etc. However, since we are interested in identifying independent variables that have significant impact on the response, we will use multinomial logistic regression as it provides a natural as well as straightforward statistical testing framework for coefficients. We first train the model on a training set containing 80% of the cleaned dataset, and check the prediction accuracy on the remaining 20% samples to check the validity of the fitted model. 

As values of the outcome variable is imbalanced, we adjust weights of samples according to the outcome category. Therefore, the cost function is now a weighted sum of entropy,
$$L(\boldsymbol\beta) = \sum_{i = 1}^n w_i \sum_{k=1}^K  I(y_i = k) \log(p_{ik}) $$
where $I(\cdot)$ is the indicator function, $w_i$ is the assigned weight and
$$p_{ik} = \frac{1}{1 + \exp(-\boldsymbol\beta_k^T \boldsymbol x_i)}$$
The weights are carefully selected such that the proportion of predicted category in the training set is in line with the actual ratio of training labels. 


## 4. Results 

We use the package nnet for fitting the multinomial logistic regression model. As shown in Table 1, the training accuracy is 64.38%. There is only a slight drop in the testing accuracy (63.90%), indicating our model does not suffer from overfitting. To see whether there is any noticeable loss of information using a linear classification model like logistic regression, we run a random forest model with 200 trees. The results are summarized in Table 1. Surprisingly, although random forest has a higher training accuracy, the prediction accuracy of the two model on test set is highly comparable, even if random forest is well capable of capturing non-linear signal. 
```{r echo = FALSE, results = 'asis'}
library(knitr)
table1 = matrix(c('64.38%', '63.90%', '95.89%', '63.09%'), nrow = 2)
rownames(table1) = c('training accuracy', 'testing accuracy')
colnames(table1) = c('logistic regression', 'random forest')
kable(table1, caption = 'Prediction Results.')
```
We now proceed with the logistic regression model. We perform the Wald test on the fitted coefficients in logistic regression. We identify significant coefficients using 0.05 as the cut-off of p-values. Figure 1 shows the significance of coefficients in the fitted logistic regression by questions. The value of "significance" is defined as follows. All insignificant coefficients are assigned 0 as the value of "significance". Then, we linearly map p-values from 0-0.05 to 1-0.5; a more significant coefficient receive a large "significance" score. Finally, the direction (sign of the fitted coefficients) is assigned to the sign of the value of "significance". The reference category is "I don't care about or I haven't thought about the future of AI.".

As shown Figure 1, people's difference in the following aspects seem to have significant impacts on their view on the future of AI: 

* Whether to take coding as a hobby (Hobby)
* Whether the respondent is a student (Student)
* What do the respondent hope to do in the next five years (HopeFiveYears)
* Whether to report or otherwise call out the unethical code in question (EthicReport)
* Whether the respondent has close dependents (Dependents)
* Job satisfaction (JobSatisfaction)
* Time spent on a desktop or laptop computer (HoursComputer)
* Age (Age)
* Experience on different operation systems (OperatingSystem)
* Number of monitors during working (NumberMonitors)

Almost all dummy variables in the above questions are significant at level of 0.05. Therefore, almost all subgroups within these questions hold some different attitude on the future of AI (compared to the reference group). There are significant coefficients in other questions, showing such difference also exists among people in other aspect other than the above listed ones. Here are some findings that we think are interesting. It is worth to mention that our findings are based on significant associations which do not guarantee a casual effect.

* Programmers who are students care more about the future of AI, and are more likely to feel excited with the possibility of AI.
* Programmers taking coding as a hobby care more about the future of AI. 

![image](p-value.png)
*Figure 1. Significance of coefficients in the fitted logistic regression by questions.*

* Programmers with a bachelor's degree in health science tend to be more worried about the potential danger of AI technology, while programmers major in humanities discipline are more likely to be exciting about the possibilities of AI. 
* Programmers who studied mathematics, statistics and information systems are less inclined to concern the danger of AI, while a undergraduate degree in social science boosts the excitement on the AI development.
* Programmers identifying them as in a competitive environment are less likely to think of the future of AI as dangerous. 
* Compared to those who use BSD/Unix the most, programmers using linux based operating system, MacOS or Windows tend to be concerned about the danger that may be raised by AI.
* Programmers who wake up before 12 p.m. at noon are more likely to be excited about the future of AI.
* Programmers who make more money are inclined to think the development of AI as exciting.
* Programmers with experiment on Python, CSS, C#, SQL, Java, Matlab, CoffeeScript, Tensorflow and Pytorch are more worried about the danger of AI.
* Programmers who are female are less worried about the dange of AI.
* Programmers identifying themselves as asexual tend to care less about the the future of AI.

There are even more significant associations and thus more interpretations can be made. However, due to the limit of the report, we cannot present all of them. Readers who are interested in this topic can explore Figure 1 as well as the coefficient matrix (lr_model_test.Rdata) on our project github website https://github.com/AChenAC/Biostat625Project. 

## 5. Conclusion 

## 6. Contribution of Group Members

## References 

1. Wang, Pei. "On Defining Artificial Intelligence" Journal of Artificial General Intelligence, vol.10, no.2, 2019, pp.1-37. https://doi.org/10.2478/jagi-2019-0002

2. Kaplan, Andreas, and Michael Haenlein. "Siri, Siri, in my hand: Who’s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence." Business Horizons 62.1 (2019): 15-25.

3. Tai, Michael Cheng-Tek. “The impact of artificial intelligence on human society and bioethics.” Tzu chi medical journal vol. 32,4 339-343. 14 Aug. 2020, doi:10.4103/tcmj.tcmj_71_20

4. McCarthy, J., Minsky, M. L., Rochester, N., & Shannon, C. E. (1955). A proposal for the Dartmouth summer research project on artificial intelligence. Available at http://www-formal.stanford.edu/jmc/history/dartmouth/dartmouth.html

5. Monett, D., and Lewis, C. W. P. 2018. Getting clarity by defining Artificial Intelligence - A Survey. In Muller, V.C., ed., Philosophy and Theory of Artificial Intelligence 2017. Berlin: Springer. 212-214.
